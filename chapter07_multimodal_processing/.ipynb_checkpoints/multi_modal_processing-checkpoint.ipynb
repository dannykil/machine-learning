{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af78a240-cba3-452b-8e9b-a85c0501be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a7d09-c6a5-45eb-bd64-dab6d5c807c6",
   "metadata": {},
   "source": [
    "# Image Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3daf661-b06e-489e-94ca-bc5b66dc1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import myvertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from vertexai.generative_models import Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25e75d-6f2c-4b62-949b-5f1686fd5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_uri = \"gs://cloud-samples-data/generative-ai/image/fruit.png\"\n",
    "# input_uri = \"https://storage.cloud.google.com/cloud-samples-data/generative-ai/image/fruit.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e3a6442-6e05-4da2-aa35-3375ef11a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/fruit.png\", \"image/png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a11bdf4-c4dc-4f83-983a-070963a816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-2.0-flash-lite-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd866b0c-57e2-4676-a7e7-d484c8e8ef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the bounding box detections:\\n```json\\n[\\n  {\"box_2d\": [2, 150, 404, 481], \"label\": \"strawberry\"},\\n  {\"box_2d\": [270, 527, 557, 770], \"label\": \"strawberry\"},\\n  {\"box_2d\": [312, 285, 788, 512], \"label\": \"peach\"},\\n  {\"box_2d\": [629, 591, 856, 933], \"label\": \"lemon\"}\\n]\\n```'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.generate_content([image_file, \"List all fruits inside image.\"])\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "645c6258-4828-4008-b02d-076286bbf47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 2 strawberries in the image.\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.generate_content([image_file, \"How many strawberrys in image?\"])\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95b26866-c7c2-4a95-b354-fd956b8e4a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the approximate nutritional values for the fruits in the image:\\n\\n**Strawberries (per 1 cup, sliced):**\\n\\n*   Calories: ~49\\n*   Carbohydrates: ~11.7g\\n*   Fiber: ~3g\\n*   Sugars: ~7.4g\\n*   Protein: ~1g\\n*   Fat: ~0.3g\\n*   Vitamin C: ~97mg (162% of the Daily Value)\\n\\n**Donut Peach (per medium fruit):**\\n\\n*   Calories: ~60\\n*   Carbohydrates: ~15g\\n*   Fiber: ~2g\\n*   Sugars: ~13g\\n*   Protein: ~1g\\n*   Fat: ~0g\\n*   Vitamin C: ~7% Daily Value\\n*   Vitamin A: ~6% Daily Value\\n\\n**Lemon (per medium lemon):**\\n\\n*   Calories: ~17\\n*   Carbohydrates: ~5.4g\\n*   Fiber: ~1.6g\\n*   Sugars: ~1.5g\\n*   Protein: ~0.6g\\n*   Fat: ~0.2g\\n*   Vitamin C: ~33mg (54% of the Daily Value)\\n\\n**Important Notes:**\\n\\n*   These values are estimates and can vary based on the size, variety, and ripeness of the fruits.\\n*   The Daily Value (DV) percentages are based on a 2,000-calorie diet.\\n*   Values are rounded for simplicity.\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.generate_content([image_file, \"Give me nutritional values of all fruits.\"])\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3195ca18-7c3a-4437-b309-49f8a7b3bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def displayMD(llmtext):\n",
    "\n",
    "    html_output = markdown.markdown(llmtext)\n",
    "    \n",
    "    custom_css = \"\"\"\n",
    "    /* 기본 스타일 초기화 (선택 사항) */\n",
    "        body {\n",
    "          margin: 0;\n",
    "          padding: 0;\n",
    "          font-family: sans-serif; /* 기본 글꼴 설정 */\n",
    "          line-height: 1.6; /* 기본 줄 간격 설정 */\n",
    "          color: #333; /* 기본 글자 색상 설정 */\n",
    "          background-color: #f4f4f4; /* 기본 배경 색상 설정 */\n",
    "        }\n",
    "        \n",
    "        /* body 태그 스타일 */\n",
    "        body {\n",
    "          padding: 20px; /* 전체 페이지 여백 */\n",
    "        }\n",
    "        \n",
    "        /* h1 태그 스타일 */\n",
    "        h1 {\n",
    "          font-size: 2.5em; /* 글자 크기 */\n",
    "          font-weight: bold; /* 글자 굵게 */\n",
    "          color: #2c3e50; /* 제목 글자 색상 */\n",
    "          margin-top: 0; /* 위쪽 여백 제거 */\n",
    "          margin-bottom: 20px; /* 아래쪽 여백 설정 */\n",
    "          border-bottom: 2px solid #3498db; /* 아래 테두리 */\n",
    "          padding-bottom: 10px; /* 아래쪽 패딩 */\n",
    "        }\n",
    "        \n",
    "        /* h2 태그 스타일 */\n",
    "        h2 {\n",
    "          font-size: 2em;\n",
    "          font-weight: semi-bold; /* 약간 굵게 */\n",
    "          color: #34495e;\n",
    "          margin-top: 30px;\n",
    "          margin-bottom: 15px;\n",
    "          border-bottom: 1px solid #95a5a6;\n",
    "          padding-bottom: 5px;\n",
    "        }\n",
    "        \n",
    "        /* h3 태그 스타일 */\n",
    "        h3 {\n",
    "          font-size: 1.7em;\n",
    "          font-weight: normal; /* 보통 굵기 */\n",
    "          color: #4a6572;\n",
    "          margin-top: 25px;\n",
    "          margin-bottom: 10px;\n",
    "        }\n",
    "        \n",
    "        /* 추가적인 스타일 (선택 사항) */\n",
    "        a {\n",
    "          color: #3498db;\n",
    "          text-decoration: none;\n",
    "        }\n",
    "        \n",
    "        a:hover {\n",
    "          text-decoration: underline;\n",
    "        }\n",
    "        \n",
    "        p {\n",
    "          margin-bottom: 15px;\n",
    "        }\n",
    "        \n",
    "        ul, ol {\n",
    "          margin-left: 20px;\n",
    "          margin-bottom: 15px;\n",
    "        }\n",
    "        \n",
    "        li {\n",
    "          margin-bottom: 5px;\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    # display(HTML(custom_css + html_output))\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50bb0120-e647-468c-ac22-fe25b0a6cedb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Here are the approximate nutritional values for the fruits in the image:</p>\n",
       "<p><strong>Strawberries (per 1 cup, sliced):</strong></p>\n",
       "<ul>\n",
       "<li>Calories: ~49</li>\n",
       "<li>Carbohydrates: ~11.7g</li>\n",
       "<li>Fiber: ~3g</li>\n",
       "<li>Sugars: ~7.4g</li>\n",
       "<li>Protein: ~1g</li>\n",
       "<li>Fat: ~0.3g</li>\n",
       "<li>Vitamin C: ~97mg (162% of the Daily Value)</li>\n",
       "</ul>\n",
       "<p><strong>Donut Peach (per medium fruit):</strong></p>\n",
       "<ul>\n",
       "<li>Calories: ~60</li>\n",
       "<li>Carbohydrates: ~15g</li>\n",
       "<li>Fiber: ~2g</li>\n",
       "<li>Sugars: ~13g</li>\n",
       "<li>Protein: ~1g</li>\n",
       "<li>Fat: ~0g</li>\n",
       "<li>Vitamin C: ~7% Daily Value</li>\n",
       "<li>Vitamin A: ~6% Daily Value</li>\n",
       "</ul>\n",
       "<p><strong>Lemon (per medium lemon):</strong></p>\n",
       "<ul>\n",
       "<li>Calories: ~17</li>\n",
       "<li>Carbohydrates: ~5.4g</li>\n",
       "<li>Fiber: ~1.6g</li>\n",
       "<li>Sugars: ~1.5g</li>\n",
       "<li>Protein: ~0.6g</li>\n",
       "<li>Fat: ~0.2g</li>\n",
       "<li>Vitamin C: ~33mg (54% of the Daily Value)</li>\n",
       "</ul>\n",
       "<p><strong>Important Notes:</strong></p>\n",
       "<ul>\n",
       "<li>These values are estimates and can vary based on the size, variety, and ripeness of the fruits.</li>\n",
       "<li>The Daily Value (DV) percentages are based on a 2,000-calorie diet.</li>\n",
       "<li>Values are rounded for simplicity.</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f6589d5-9442-40ae-96b9-04903989e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>You have to fill out information in the following sections:</p>\n",
       "<ul>\n",
       "<li><strong>Personal Information:</strong> Full Name, Address, Phone Number, Email Address</li>\n",
       "<li><strong>Education:</strong> Degree(s) Obtained, University/Institution, Years Attended, GPA (if applicable)</li>\n",
       "<li><strong>Relevant Experience (for each experience):</strong> Company Name, Position Title, Years of Experience, Key Responsibilities and Accomplishments</li>\n",
       "<li><strong>Addition Questions:</strong> Answer the questions provided.</li>\n",
       "</ul>\n",
       "<p>So, you need to fill in 10-12 fields for a complete application, plus the answers for the additional questions.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_file = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/job_application.png\", \"image/png\")\n",
    "res = model.generate_content([image_file, \"How many information I have to fill out?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fd59e353-3f12-456d-a30c-4b5a467b96a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>There are two players in the image.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_file = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/cricket.jpeg\", \"image/jpeg\")\n",
    "res = model.generate_content([image_file, \"How many players in image?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfb62a-7c55-46ce-afbe-843b4b8360dc",
   "metadata": {},
   "source": [
    "# Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "610527ed-71ae-40b5-8b7e-8b882045286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Here's a short description of each picture:</p>\n",
       "<p><strong>Picture 1:</strong> Shows a precarious structure built from colorful wooden blocks. The blocks are stacked in a seemingly unstable manner, creating a playful and slightly chaotic arrangement.</p>\n",
       "<p><strong>Picture 2:</strong> Displays a pyramid-like structure made from colorful wooden blocks. The blocks are neatly arranged, forming a stable and balanced structure.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/blocks-1.jpg\", \"image/jpeg\")\n",
    "image_file2 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/blocks-2.jpg\", \"image/jpeg\")\n",
    "# image_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/image/cricket.jpeg\", \"image/jpeg\")\n",
    "\n",
    "res = model.generate_content([image_file1, image_file2, \"Can you describe about both of these pictures shortly?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43330c2c-e124-4b59-9c4e-4fe95c59fd7a",
   "metadata": {},
   "source": [
    "# Video Processing in LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c0c8913-836a-4df9-9d42-b9a82fe5224f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Here's a description of the video:</p>\n",
       "<p><strong>Overall Impression:</strong></p>\n",
       "<p>The video shows a man rock climbing indoors. He's well-equipped with a harness, shoes, and chalk bag, and appears to be working his way up the climbing wall. The shot is angled to show the wall at a diagonal, adding a sense of depth.</p>\n",
       "<p><strong>Details:</strong></p>\n",
       "<ul>\n",
       "<li><strong>The Climber:</strong> A young man with short hair. He is wearing a black t-shirt with text on the back that can be read as \"KOMAHAA CKANASPOMA\" on the back and dark shorts. He wears a harness and climbing shoes.</li>\n",
       "<li><strong>The Climbing Wall:</strong> The wall has various colored climbing holds, including those in orange, green, blue, and white. The wall has several sections in different colors. There are sections of the wall that are made of what looks like plywood painted in different colors, for example, the red sections.</li>\n",
       "<li><strong>Action:</strong> The climber makes moves to the next handhold, secures a rope, and continues climbing upwards. He seems to be focused and deliberate.</li>\n",
       "<li><strong>Safety:</strong> The rope is attached and suggests this is a lead climb, and the climber is safely belayed.</li>\n",
       "</ul>\n",
       "<p><strong>In essence, the video showcases a dynamic, athletic activity of indoor rock climbing.</strong></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/video/describe_video_content.mp4\", \"video/mp4\")\n",
    "\n",
    "res = model.generate_content([video_file1, \"Can you describe about this video?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099762d5-a5e4-40d8-9c55-da92cd6b0d45",
   "metadata": {},
   "source": [
    "# Audio Processing(ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b2829cd-f020-4e32-9897-8ff90107214b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Request contains an invalid argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_interceptor.py:332\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    329\u001b[39m call = \u001b[38;5;28mself\u001b[39m._interceptor.intercept_unary_unary(\n\u001b[32m    330\u001b[39m     continuation, client_call_details, request\n\u001b[32m    331\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_channel.py:440\u001b[39m, in \u001b[36m_InactiveRpcError.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_channel.py:1198\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1192\u001b[39m (\n\u001b[32m   1193\u001b[39m     state,\n\u001b[32m   1194\u001b[39m     call,\n\u001b[32m   1195\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1196\u001b[39m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1197\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/grpc/_channel.py:1006\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Request contains an invalid argument.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.207.106:443 {grpc_message:\"Request contains an invalid argument.\", grpc_status:3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 400 Request contains an invalid argument. 오류남....왜?\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# model = GenerativeModel(\"gemini-2.0-flash-lite-001\")\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# model = GenerativeModel(\"gemini-2.0-flash-001\")\u001b[39;00m\n\u001b[32m      4\u001b[39m audio_file1 = Part.from_uri(\u001b[33m\"\u001b[39m\u001b[33mgs://cloud-samples-data/generative-ai/audio/pixel.mp3 \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maudio/mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maudio_file1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCan you summarise about this audio file?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m displayMD(res.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:695\u001b[39m, in \u001b[36m_GenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[39m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content_streaming(\n\u001b[32m    687\u001b[39m         contents=contents,\n\u001b[32m    688\u001b[39m         generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         labels=labels,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:820\u001b[39m, in \u001b[36m_GenerativeModel._generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[39m\n\u001b[32m    793\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[32m    794\u001b[39m \n\u001b[32m    795\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    810\u001b[39m \u001b[33;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m    813\u001b[39m     contents=contents,\n\u001b[32m    814\u001b[39m     generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    818\u001b[39m     labels=labels,\n\u001b[32m    819\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m gapic_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response(gapic_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2276\u001b[39m, in \u001b[36mPredictionServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m   2273\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m   2275\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2276\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2281\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2283\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m   2284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mInvalidArgument\u001b[39m: 400 Request contains an invalid argument."
     ]
    }
   ],
   "source": [
    "# 400 Request contains an invalid argument. 오류남....왜?\n",
    "# model = GenerativeModel(\"gemini-2.0-flash-lite-001\")\n",
    "# model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "audio_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/audio/pixel.mp3 \", \"audio/mp3\")\n",
    "\n",
    "res = model.generate_content([audio_file1, \"Can you summarise about this audio file?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fc9fb-eea4-40cd-b782-5857b0e33dad",
   "metadata": {},
   "source": [
    "# Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e184ecd-cb7e-4283-a7d0-e3c34541e9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>This PDF document is a marketing brochure for Google BigQuery, a real-time big data analytics service offered by Google Cloud. It highlights the service's key features, benefits, and use cases.</p>\n",
       "<p><strong>Key takeaways include:</strong></p>\n",
       "<ul>\n",
       "<li><strong>Functionality:</strong> BigQuery enables users to analyze massive datasets (terabytes and beyond) using SQL-like queries, allowing for real-time insights. It offers features for data storage, processing, and accessibility.</li>\n",
       "<li><strong>Benefits:</strong> Key advantages include scalability, speed and flexibility (ad hoc queries, familiar syntax), integration with other Google services (e.g., Google Sheets), and ease of use (simple UI and REST interface). Users can gain insights from big data quickly without upfront hardware or software investment.</li>\n",
       "<li><strong>Use Cases:</strong> Examples are provided, such as ad hoc reporting, segmentation analysis, and monitoring dashboards.</li>\n",
       "<li><strong>Pricing:</strong> The service is designed with a pay-as-you-go model.</li>\n",
       "<li><strong>Security and Reliability:</strong> The document emphasizes the secure, reliable infrastructure, data replication, and access controls.</li>\n",
       "<li><strong>Target Audience:</strong> The brochure is aimed at businesses and developers needing to gain insights from large amounts of data.</li>\n",
       "</ul>\n",
       "<p>In essence, the document serves as an introduction and overview of Google BigQuery's capabilities, highlighting its advantages and benefits to potential customers.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input_uri = \"https://storage.cloud.google.com/cloud-samples-data/generative-ai/pdf/BigQuery.pdf\"\n",
    "# document_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/pdf/BigQuery.pdf \", \"application/pdf\")\n",
    "document_file1 = Part.from_uri(\"gs://batch_data_embedding/generative-ai_pdf_BigQuery.pdf\", \"application/pdf\")\n",
    "\n",
    "res = model.generate_content([document_file1, \"Can you summarise about this pdf file?\"])\n",
    "displayMD(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3d5b07f-e1e8-4398-899f-6806e4c47188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The keyword \"public\" appears 6 times in the text.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_file1 = Part.from_uri(\"gs://cloud-samples-data/generative-ai/text/book.txt\", \"text/plain\")\n",
    "\n",
    "# res = model.generate_content([document_file1, \"Can you summarise about this pdf file?\"])\n",
    "res = model.generate_content([document_file1, \"How many times 'public' keyword appear?\"])\n",
    "displayMD(res.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env]",
   "language": "python",
   "name": "conda-env-ml_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
